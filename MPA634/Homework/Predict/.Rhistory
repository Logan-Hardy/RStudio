model <- randomForest(Status ~ ., data = train, ntrees = 500, proximity = TRUE, mtry=4)
model
predicted <- predict(model, test)
cm2 <- confusion_matrix(test$Status, predicted)
plot_confusion_matrix(cm2$`Confusion Matrix`[[1]])
importance(model) %>%
as.data.frame() %>%
tibble::rownames_to_column() %>%
ggplot(aes(y = fct_reorder(rowname, MeanDecreaseGini), x = MeanDecreaseGini, fill = rowname)) +
geom_col() +
labs(title = "Importance of Variables in Model",
x = "Importance",
y = "Variables") +
theme_minimal() +
theme(legend.position = "none")
train %>%
GGally::ggparcoord(
columns = c(1:10),
groupColumn = 7,
showPoints = TRUE,
title = "Title",
alphaLines = 0.2
) +
viridis::scale_color_viridis(discrete=TRUE) +
theme_minimal() +
theme(legend.key  = element_rect(fill = "#ffffff"))
View(life_expectancy_no_nas)
train %>%
GGally::ggparcoord(
columns = c(1:10),
groupColumn = 1,
showPoints = TRUE,
title = "Title",
alphaLines = 0.2
) +
viridis::scale_color_viridis(discrete=TRUE) +
theme_minimal() +
theme(legend.key  = element_rect(fill = "#ffffff"))
View(train)
train %>%
GGally::ggparcoord(
columns = c(1:10),
groupColumn = 3,
showPoints = TRUE,
title = "Title",
alphaLines = 0.2
) +
viridis::scale_color_viridis(discrete=TRUE) +
theme_minimal() +
theme(legend.key  = element_rect(fill = "#ffffff"))
train %>%
GGally::ggparcoord(
columns = c(1:10),
groupColumn = 1,
showPoints = TRUE,
title = "Title",
alphaLines = 0.2
) +
viridis::scale_color_viridis(discrete=TRUE) +
theme_minimal() +
theme(legend.key  = element_rect(fill = "#ffffff"))
View(train)
sum(is.na(train$Status))
fct_count(life_expectancy_no_nas$Status)
train %>%
GGally::ggparcoord(
columns = c(1:10),
groupColumn = 1,
showPoints = TRUE,
title = "Parallel Coordinate Plot of Status",
alphaLines = 0.5
) +
viridis::scale_color_viridis(discrete=TRUE) +
theme_minimal() +
theme(legend.key  = element_rect(fill = "#ffffff"))
train %>% na.omit()
model <- randomForest(life_expectancy ~ ., data = train, ntrees = 500, proximity = TRUE, mtry=4)
model <- randomForest(Life_expectancy ~ ., data = test, ntrees = 500, proximity = TRUE, mtry=4)
model
mds_data <- as.dist(1-model$proximity) %>% cmdscale(eig=TRUE, x.ret=TRUE)
mds_data <- as.dist(1-model$proximity) %>% cmdscale(eig=TRUE, x.ret=TRUE)
mds_data$points %>%
as.data.frame() %>%
ggplot(aes(x = V1, y = V2)) +
geom_point(aes(color = train$owner), alpha = .5) +
theme_minimal() +
ggtitle("MDS plot using (1 - Random Forest Proximities)")
train %>%
GGally::ggparcoord(
columns = c(1:10),
groupColumn = 1,
showPoints = TRUE,
title = "Parallel Coordinate Plot of Status",
alphaLines = 0.5
) +
viridis::scale_color_viridis(discrete=TRUE) +
theme_minimal() +
theme(legend.key  = element_rect(fill = "#ffffff"))
train %>%
GGally::ggparcoord(
columns = c(1:9),
groupColumn = 1,
showPoints = TRUE,
title = "Parallel Coordinate Plot of Status",
alphaLines = 0.5
) +
viridis::scale_color_viridis(discrete=TRUE) +
theme_minimal() +
theme(legend.key  = element_rect(fill = "#ffffff"))
train %>%
GGally::ggparcoord(
columns = c(2:10),
groupColumn = 1,
showPoints = TRUE,
title = "Parallel Coordinate Plot of Status",
alphaLines = 0.5
) +
viridis::scale_color_viridis(discrete=TRUE) +
theme_minimal() +
theme(legend.key  = element_rect(fill = "#ffffff"))
train %>%
GGally::ggparcoord(
columns = c(2:10),
groupColumn = 1,
showPoints = TRUE,
title = "Parallel Coordinate Plot of Status",
alphaLines = 0.5
) +
viridis::scale_color_viridis(discrete=TRUE) +
theme_minimal() +
theme(legend.key  = element_rect(fill = "#ffffff"))
life_expectancy <- read_csv("../../Data/Life Expectancy.csv") %>% mutate_if(is.character, as.factor)
life_expectancy <- read_csv("../../Data/Life Expectancy Data.csv") %>% mutate_if(is.character, as.factor)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(mclust)
library(mclust)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(mclust)
covid_numbers_feb_2022 <- read_csv("../../Data/covid_numbers_feb_2022.csv")
View(covid_numbers_feb_2022)
covid_clean <- covid_numbers_feb_2022 %>%
# Removing large factor and character columns
select(-state, -county, -state.y, -fips) %>%
# Simplifying mask requirement
mutate(mask_requirement2020 = fct_lump(mask_requirement2020, n = 2)) %>%
# Creating dummy columns
fastDummies::dummy_cols(remove_first_dummy = TRUE,
ignore_na = TRUE,
remove_selected_columns = TRUE) %>%
# Making variables per capita
mutate(icu_beds_per_cap = icu_beds/POPESTIMATE2020,
cases_per_cap = cases/POPESTIMATE2020) %>%
select(-cases, -icu_beds) %>%
# Replacing missing values with mean
mutate(across(where(is.numeric), ~replace_na(.x, mean(.x, na.rm = TRUE)))) %>%
# Scaling the data with z score standardization
scale() %>%
as_tibble()
covid_clean <- covid_numbers_feb_2022 %>%
# Removing large factor and character columns
select(-state, -county, -state.y, -fips) %>%
# Simplifying mask requirement
mutate(mask_requirement2020 = fct_lump(mask_requirement2020, n = 2)) %>%
# Creating dummy columns
fastDummies::dummy_cols(remove_first_dummy = TRUE,
ignore_na = TRUE,
remove_selected_columns = TRUE) %>%
# Making variables per capita
mutate(icu_beds_per_cap = icu_beds/POPESTIMATE2020,
cases_per_cap = cases/POPESTIMATE2020) %>%
select(-cases, -icu_beds) %>%
# Replacing missing values with mean
mutate(across(where(is.numeric), ~replace_na(.x, mean(.x, na.rm = TRUE)))) %>%
# Scaling the data with z score standardization
scale() %>%
as_tibble()
# Since we have so many variables, let's just plot the first 8.
plot(covid_clean[1:8])
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(mclust)
covid_clean <- covid_numbers_feb_2022 %>%
# Removing large factor and character columns
select(-state, -county, -state.y, -fips) %>%
# Simplifying mask requirement
mutate(mask_requirement2020 = fct_lump(mask_requirement2020, n = 2)) %>%
# Creating dummy columns
fastDummies::dummy_cols(remove_first_dummy = TRUE,
ignore_na = TRUE,
remove_selected_columns = TRUE) %>%
# Making variables per capita
mutate(icu_beds_per_cap = icu_beds/POPESTIMATE2020,
cases_per_cap = cases/POPESTIMATE2020) %>%
select(-cases, -icu_beds) %>%
# Replacing missing values with mean
mutate(across(where(is.numeric), ~replace_na(.x, mean(.x, na.rm = TRUE)))) %>%
# Scaling the data with z score standardization
scale() %>%
as_tibble()
covid_clean <- covid_numbers_feb_2022 %>%
# Removing large factor and character columns
select(-state, -county, -state.y, -fips) %>%
# Simplifying mask requirement
mutate(mask_requirement2020 = fct_lump(mask_requirement2020, n = 2)) %>%
# Creating dummy columns
fastDummies::dummy_cols(remove_first_dummy = TRUE,
ignore_na = TRUE,
remove_selected_columns = TRUE) %>%
# Making variables per capita
mutate(icu_beds_per_cap = icu_beds/POPESTIMATE2020,
cases_per_cap = cases/POPESTIMATE2020) %>%
select(-cases, -icu_beds) %>%
# Replacing missing values with mean
mutate(across(where(is.numeric), ~replace_na(.x, median(.x, na.rm = TRUE)))) %>%
# Scaling the data with z score standardization
scale() %>%
as_tibble()
# Since we have so many variables, let's just plot the first 8.
plot(covid_clean[1:8])
wss <- (nrow(covid_clean)-1)*sum(apply(covid_clean,2,var))
for (i in 2:15) wss[i] <- sum(kmeans(covid_clean, centers=i)$withinss)
plot(1:15, wss, type="b", xlab="Number of Clusters",
ylab="Within groups sum of squares")
plot(1:50, wss, type="b", xlab="Number of Clusters",
ylab="Within groups sum of squares")
plot(1:15, wss, type="b", xlab="Number of Clusters",
ylab="Within groups sum of squares")
# K-Means Cluster Analysis
(fit <- kmeans(covid_clean, 4))
wss <- (nrow(covid_clean)-1)*sum(apply(covid_clean,2,var))
for (i in 2:15) wss[i] <- sum(kmeans(covid_clean, centers=i)$withinss)
plot(1:15, wss, type="b", xlab="Number of Clusters",
ylab="Within groups sum of squares")
# K-Means Cluster Analysis
(fit <- kmeans(covid_clean, 4))
# K-Means Cluster Analysis
(fit <- kmeans(covid_clean, 4))
# Make a new dataset called covid_clusters with the clusters appended as a new variable
covid_clusters <- cbind(covid_clean, fir$cluster)
# Make a new dataset called covid_clusters with the clusters appended as a new variable
covid_clusters <- cbind(covid_clean, fit$cluster)
covid_clusters
plot(covid_clusters[1:8], col = fit$cluster)
# Here is our sample dataset of 20 values
sample_covid <- sample_n(covid_clean, 20)
# Make a distance matrix
d <- dist(sample_covid)
# Print it out
round(d, 2)
fitH <- hclust(d)
plot(fitH)
# We can see how these clusters show up in our correlation matrix
clusters <- cutree(fitH, k = 4)
plot(sample_covid[1:8], col = clusters)
# Make a distance matrix
d <- dist(covid_clean)
# Plot it
fitH <- hclust(d)
plot(fitH)
# Use clusters to plot correlation matrix
clusters <- cutree(fitH, k = 4)
plot(covid_clean[1:8], col = clusters)
# Use clusters to plot correlation matrix
clusters <- cutree(fitH, k = 7)
plot(covid_clean[1:8], col = clusters)
# Use clusters to plot correlation matrix
clusters <- cutree(fitH, k = 10)
plot(covid_clean[1:8], col = clusters)
# Use the Mclust function to run several clustering algorithms at once.
fitM <- Mclust(covid_clean, G = 2:10)
# Print the model
fitM
# Use the Mclust function to run several clustering algorithms at once.
fitM <- Mclust(covid_clean)
# Use the Mclust function to run several clustering algorithms at once.
fitM <- Mclust(covid_clean)
# Print the model
fitM
# Use the Mclust function to run several clustering algorithms at once.
fitM <- Mclust(covid_clean, G = 2:10)
# Print the model
fitM
# Plot the model
plot(fitM)
4
5
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(mclust)
life_expectancy <- read_csv("../../Data/Life Expectancy Data.csv") %>% mutate_if(is.character, as.factor)
life_expectancy <- read_csv("../../Data/Life Expectancy Data.csv") %>% mutate_if(is.character, as.factor) %>% filter(max(Year))
View(life_expectancy)
life_expectancy <- read_csv("../../Data/Life Expectancy Data.csv") %>% mutate_if(is.character, as.factor) %>% filter(Year == max(Year))
life_expectancy <- read_csv("../../Data/Life Expectancy Data.csv") %>% mutate_if(is.character, as.factor) %>% filter(Year == 2015)
life_expectancy <- read_csv("../../Data/Life Expectancy Data.csv") %>% mutate_if(is.character, as.factor) %>% filter(Year == max(Year))
life_exp_clean <- Life_Expectancy_Data %>%
# Removing large factor
select(-Country, -Year) %>%
# Creating dummy columns
fastDummies::dummy_cols(remove_first_dummy = TRUE,
ignore_na = TRUE,
remove_selected_columns = TRUE) %>%
# Replacing missing values with median
mutate(across(where(is.numeric), ~replace_na(.x, median(.x, na.rm = TRUE)))) %>%
# Scaling the data with z score standardization
scale() %>%
as_tibble()
Life_Expectancy_Data <- read_csv("../../Data/Life Expectancy Data.csv") %>% mutate_if(is.character, as.factor) %>% filter(Year == max(Year))
life_exp_clean <- Life_Expectancy_Data %>%
# Removing large factor
select(-Country, -Year) %>%
# Creating dummy columns
fastDummies::dummy_cols(remove_first_dummy = TRUE,
ignore_na = TRUE,
remove_selected_columns = TRUE) %>%
# Replacing missing values with median
mutate(across(where(is.numeric), ~replace_na(.x, median(.x, na.rm = TRUE)))) %>%
# Scaling the data with z score standardization
scale() %>%
as_tibble()
colnames(life_exp_clean) <- str_replace_all(colnames(life_exp_clean),
c(" " = "_",
"-" = "_",
"/" = "_"))
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(mclust)
covid_numbers_feb_2022 <- read_csv("~/Desktop/R Working Directory/Datasets for playing/COVID Data/UPDATE Covid Counties and States Feb 2022/covid_numbers_feb_2022.csv")
covid_numbers_feb_2022 <- read_csv("../../Data/covid_numbers_feb_2022.csv")
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(mclust)
covid_numbers_feb_2022 <- read_csv("../../Data/covid_numbers_feb_2022.csv")
covid_clean <- covid_numbers_feb_2022 %>%
# Removing large factor and character columns
select(-state, -county, -state.y, -fips) %>%
# Simplifying mask requirement
mutate(mask_requirement2020 = fct_lump(mask_requirement2020, n = 2)) %>%
# Creating dummy columns
fastDummies::dummy_cols(remove_first_dummy = TRUE,
ignore_na = TRUE,
remove_selected_columns = TRUE) %>%
# Making variables per capita
mutate(icu_beds_per_cap = icu_beds/POPESTIMATE2020,
cases_per_cap = cases/POPESTIMATE2020) %>%
select(-cases, -icu_beds) %>%
# Replacing missing values with mean
mutate(across(where(is.numeric), ~replace_na(.x, mean(.x, na.rm = TRUE)))) %>%
# Scaling the data with z score standardization
scale() %>%
as_tibble()
covid_clean <- covid_numbers_feb_2022 %>%
# Removing large factor and character columns
select(-state, -county, -state.y, -fips) %>%
# Simplifying mask requirement
mutate(mask_requirement2020 = fct_lump(mask_requirement2020, n = 2)) %>%
# Creating dummy columns
fastDummies::dummy_cols(remove_first_dummy = TRUE,
ignore_na = TRUE,
remove_selected_columns = TRUE) %>%
# Making variables per capita
mutate(icu_beds_per_cap = icu_beds/POPESTIMATE2020,
cases_per_cap = cases/POPESTIMATE2020) %>%
select(-cases, -icu_beds) %>%
# Replacing missing values with mean
mutate(across(where(is.numeric), ~replace_na(.x, median(.x, na.rm = TRUE)))) %>%
# Scaling the data with z score standardization
scale() %>%
as_tibble()
# Since we have so many variables, let's just plot the first 8.
plot(covid_clean[1:8])
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(mclust)
covid_numbers_feb_2022 <- read_csv("../../Data/covid_numbers_feb_2022.csv")
covid_clean <- covid_numbers_feb_2022 %>%
# Removing large factor and character columns
select(-state, -county, -state.y, -fips) %>%
# Simplifying mask requirement
mutate(mask_requirement2020 = fct_lump(mask_requirement2020, n = 2)) %>%
# Creating dummy columns
fastDummies::dummy_cols(remove_first_dummy = TRUE,
ignore_na = TRUE,
remove_selected_columns = TRUE) %>%
# Making variables per capita
mutate(icu_beds_per_cap = icu_beds/POPESTIMATE2020,
cases_per_cap = cases/POPESTIMATE2020) %>%
select(-cases, -icu_beds) %>%
# Replacing missing values with mean
mutate(across(where(is.numeric), ~replace_na(.x, median(.x, na.rm = TRUE)))) %>%
# Scaling the data with z score standardization
scale() %>%
as_tibble()
# Since we have so many variables, let's just plot the first 8.
plot(covid_clean[1:8])
wss <- (nrow(covid_clean)-1)*sum(apply(covid_clean,2,var))
for (i in 2:15) wss[i] <- sum(kmeans(covid_clean, centers=i)$withinss)
plot(1:15, wss, type="b", xlab="Number of Clusters",
ylab="Within groups sum of squares")
# K-Means Cluster Analysis
(fit <- kmeans(covid_clean, 4))
# Make a new dataset called covid_clusters with the clusters appended as a new variable
covid_clusters <- covid_clean %>% mutate(clusters = fit$cluster)
plot(covid_clusters[1:8], col = covid_clusters$clusters)
plot(Life_Expectancy_Data[1:10])
corr_matrix <- cor(life_expectancy_no_nas)
corr_matrix <- cor(Life_Expectancy_Data[1:10])
View(Life_Expectancy_Data)
life_exp_clean <- Life_Expectancy_Data %>%
# Removing large factor
select(-Country, -Year) %>%
# Creating dummy columns
fastDummies::dummy_cols(remove_first_dummy = TRUE,
ignore_na = TRUE,
remove_selected_columns = TRUE) %>%
# Replacing missing values with median
mutate(across(where(is.numeric), ~replace_na(.x, mean(.x, na.rm = TRUE)))) %>%
# Scaling the data with z score standardization
scale() %>%
as_tibble()
View(life_expectancy)
View(life_exp_clean)
plot(life_exp_clean[1:10])
corr_matrix <- cor(life_exp_clean[1:10])
corrplot(corr_matrix, method="color", type="lower", tl.cex = .8)
library(corrplot)
corrplot(corr_matrix, method="color", type="lower", tl.cex = .8)
plot(life_exp_clean[1:10])
corr_matrix <- cor(life_exp_clean[1:10])
corrplot(corr_matrix, method="color", type="lower", tl.cex = .8)
# plotted correlation matrix
plot(life_exp_clean[1:10])
# colored correlation matrix
corr_matrix <- cor(life_exp_clean[1:10])
corrplot(corr_matrix, method="color", type="lower", tl.cex = .8)
life_exp_clean <- Life_Expectancy_Data %>%
# Removing large factor
select(-Country, -Year) %>%
# Creating dummy columns
fastDummies::dummy_cols(remove_first_dummy = TRUE,
ignore_na = TRUE,
remove_selected_columns = TRUE) %>%
# Replacing missing values with median
mutate(across(where(is.numeric), ~replace_na(.x, median(.x, na.rm = TRUE)))) %>%
# Scaling the data with z score standardization
scale() %>%
as_tibble()
colnames(life_exp_clean) <- str_replace_all(colnames(life_exp_clean),
c(" " = "_",
"-" = "_",
"/" = "_"))
# plotted correlation matrix
plot(life_exp_clean[1:10])
# colored correlation matrix
corr_matrix <- cor(life_exp_clean[1:10])
corrplot(corr_matrix, method="color", type="lower", tl.cex = .8)
wss <- (nrow(life_exp_clean)-1)*sum(apply(life_exp_clean,2,var))
for (i in 2:15) wss[i] <- sum(kmeans(life_exp_clean, centers=i)$withinss)
plot(1:15, wss, type="b", xlab="Number of Clusters",
ylab="Within groups sum of squares")
wss <- (nrow(life_exp_clean)-1)*sum(apply(life_exp_clean,2,var))
for (i in 2:15) wss[i] <- sum(kmeans(life_exp_clean, centers=i)$withinss)
plot(1:15, wss, type="b", xlab="Number of Clusters",
ylab="Within groups sum of squares")
(fit <- kmeans(life_exp_clean, 7))
(fit <- kmeans(life_exp_clean, 7))
(fit <- kmeans(life_exp_clean, 7))
(fit <- kmeans(life_exp_clean, 6))
(fit <- kmeans(life_exp_clean, 5))
(fit <- kmeans(life_exp_clean, 4))
(fit <- kmeans(life_exp_clean, 6))
(fit <- kmeans(life_exp_clean, 9))
(fit <- kmeans(life_exp_clean, 7))
life_exp_clusters <- life_exp_clean %>% mutate(clusters = fit$cluster)
plot(life_exp_clusters[1:10], col = life_exp_clusters$clusters)
# Make a distance matrix
d <- dist(life_exp_clusters, labels=life_expectancy$Country)
sample_covid <- sample_n(covid_clean, 20)
# Make a distance matrix
d <- dist(sample_covid)
# Print it out
round(d, 2)
fitH <- hclust(d)
plot(fitH)
# Make a distance matrix
d <- dist(life_exp_clusters)
# Print it out
round(d, 2)
fitH <- hclust(d)
plot(fitH, labels=life_expectancy$Country)
View(Life_Expectancy_Data)
# Make a distance matrix
d <- dist(life_exp_clusters)
# Print it out
round(d, 2)
fitH <- hclust(d)
plot(fitH, labels=life_expectancy$Country)
# Make a distance matrix
d <- dist(life_exp_clusters)
# Print it out
round(d, 2)
fitH <- hclust(d)
plot(fitH, labels=life_expectancy$Country)
clusters <- cutree(fitH, k = 4)
plot(sample_covid[1:8], col = clusters)
clusters <- cutree(fitH, k = 7)
plot(life_exp_clusters[1:10], col = clusters)
(fitM <- Mclust(life_exp_clusters))
(fitM <- Mclust(life_exp_clean))
plot(fitM)
