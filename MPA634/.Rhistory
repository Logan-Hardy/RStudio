model_accuracy <- cbind(predicted, actual) %>%
as_tibble() %>%
mutate(difference = predicted-actual,
abs_difference = abs(difference),
sqr_difference = difference*difference)
RMSE(predicted, actual)
MAE(predicted, actual)
normalize <- function(x) {
return((x- min(x, na.rm = TRUE)) /(max(x, na.rm = TRUE)-min(x, na.rm = TRUE)))
}
min_max <- as.data.frame(lapply(mpg_clean, normalize))
model_min_max <- lm(MPG~.,min_max)
model_min_max <- lm(MPG~.,min_max)
# Load data and make copy
mpg <- read_csv("../Data/mpg.csv")
mpg_copy <- mpg
## Clean.1 & Transform.5
#Write one custom function and Use at least 2 of the NA techniques we learned
# Function to eliminate all NAs in a dataframe
eliminate_all_NAs <- function(df) {
# Get rid of Columns that only have NAs / that are empty
empty_columns <- colSums(is.na(df)) == nrow(df)
df <- df[, !empty_columns]
# Get rid of rows with NAs
df <- df %>% na.omit()
return(df)
}
# Call function to eliminate all NAs from dataframe
mpg_copy <- eliminate_all_NAs(mpg_copy)
## Transform 3
# You must provide well designed graphs of your data. Each must be well labeled and have some sort of default or custom theme applied.
mpg <- mpg %>% mutate(Cylinders = as.factor(Cylinders))
# Boxplot of pet lisence types
mpg_copy %>%
ggplot(aes(x = fct_reorder(Cylinders, MPG, median, na.rm = TRUE), y = MPG, fill = Cylinders)) +
geom_boxplot(outlier.alpha = .1) +
labs(title = "Boxplot of Cylinders and MPG",
subtitle = "Notice how 4 cylinders have highest MPG",
x = "") +
theme_new +
theme(axis.title = element_text(size = 10, color = "grey40"),
axis.title.x = element_text(hjust = .02, vjust = .4),
legend.position = "none")
## Transform 3
# You must provide well designed graphs of your data. Each must be well labeled and have some sort of default or custom theme applied.
mpg <- mpg %>% mutate(Cylinders = as.factor(Cylinders))
# Boxplot of pet lisence types
mpg %>%
ggplot(aes(x = fct_reorder(Cylinders, MPG, median, na.rm = TRUE), y = MPG, fill = Cylinders)) +
geom_boxplot(outlier.alpha = .1) +
labs(title = "Boxplot of Cylinders and MPG",
subtitle = "Notice how 4 cylinders have highest MPG",
x = "") +
theme_new +
theme(axis.title = element_text(size = 10, color = "grey40"),
axis.title.x = element_text(hjust = .02, vjust = .4),
legend.position = "none")
## Transform.6
# Find average/median numbers of MPG by cylinders
mpg %>% select(MPG, Cylinders) %>% group_by(Cylinders) %>% summarise(mean = mean(MPG), median = median(MPG))
## Transform 1&2
# Use the following functions - filter, mutate, select, summarize, group_by, arrange. (May be helpful after cleaning)
# Fiter
# Filter to see acceleration greater than 20
mpg_reduced <- mpg_copy %>% filter(Acceleration > 20)
# Mutate
# create new column that is the ratio of horse_power to displacement
mpg_copy <- mpg_copy %>% mutate(hp_per_displacement =
(Horse_Power /Displacement))
library(corrplot)
library(caret)
library(VIM)
mpg_clean <- mpg_copy %>% select(-Name)
mpg_copy <- mpg_copy %>% mutate(Cylinders = as.numeric(Cylinders))
model <- lm(MPG~.,mpg_clean)
summary(model)
predicted <- predict(model)
actual <- mpg_clean$MPG
# cbind them together, then pipe into as_tibble(). Mutate the other columns, and save the dataset as model_accuracy.
model_accuracy <- cbind(predicted, actual) %>%
as_tibble() %>%
mutate(difference = predicted-actual,
abs_difference = abs(difference),
sqr_difference = difference*difference)
RMSE(predicted, actual)
MAE(predicted, actual)
normalize <- function(x) {
return((x- min(x, na.rm = TRUE)) /(max(x, na.rm = TRUE)-min(x, na.rm = TRUE)))
}
min_max <- as.data.frame(lapply(mpg_clean, normalize))
model_min_max <- lm(MPG~.,min_max)
summary(model_min_max)
# Split data into train and test groups
source("../Homework/Predict/preprocessing_functions.R")
set.seed(21)
sample <- trainIndex <- createDataPartition(mpg_clean$MPG, p = .85,
list = FALSE,
times = 1)
train <- mpg_clean[sample,]
test <- mpg_clean[-sample,]
# Process train and test data (eliminated 4 columns)
train_processed <- train %>%
remove_empty() %>%
lump_factors(label = MPG, remove_label = FALSE) %>%
impute() %>%
remove_near_zero() %>%
remove_linear_combos() %>%
remove_correlated()
test_processed <- test %>%
remove_empty() %>%
lump_factors(label = MPG, remove_label = FALSE) %>%
impute() %>%
select(colnames(train_processed))
# Lasso
model_lasso <- classification_train(mpg_clean, "MPG", method = "lasso")
# Linear Regression
model_lm <- classification_train(mpg_clean, "MPG", method = "lm")
# Elasticnet
model_enet <- classification_train(mpg_clean, "MPG", method = "enet")
# Accuracy of lda model
predicted <- predict(model_lasso, test_processed)
test_processed
model_lasso
# Accuracy of lda model
predicted <- predict(model_lasso, mpg_clean)
print(paste0("RMSE: ", round(RMSE(predicted, test_processed$MPG), 3), "   MAE: ",
round(MAE(predicted, test_processed$MPG), 3)))
# Lasso
model_lasso <- classification_train(train_processed, "MPG", method = "lasso")
# Linear Regression
model_lm <- classification_train(train_processed, "MPG", method = "lm")
# Elasticnet
model_enet <- classification_train(train_processed, "MPG", method = "enet")
# Accuracy of lda model
predicted <- predict(model_lasso, test_processed)
print(paste0("RMSE: ", round(RMSE(predicted, test_processed$MPG), 3), "   MAE: ",
round(MAE(predicted, test_processed$MPG), 3)))
# Accuracy of random forest model
predicted <- predict(model_lm, test_processed)
print(paste0("RMSE: ", round(RMSE(predicted, test_processed$MPG), 3), "   MAE: ",
round(MAE(predicted, test_processed$MPG), 3)))
# Accuracy of svm model
predicted <- predict(model_enet, test_processed)
print(paste0("RMSE: ", round(RMSE(predicted, test_processed$MPG), 3), "   MAE: ",
round(MAE(predicted, test_processed$MPG ), 3)))
predicted
install.packages("brnn")
library(brnn)
# Lasso
model_lasso <- classification_train(train_processed, "MPG", method = "brnn")
# Accuracy of lda model
predicted <- predict(model_lasso, test_processed)
print(paste0("RMSE: ", round(RMSE(predicted, test_processed$MPG), 3), "   MAE: ",
round(MAE(predicted, test_processed$MPG), 3)))
# Accuracy of lda model
predicted <- predict(model_lasso, test_processed)
print(paste0("RMSE: ", round(RMSE(predicted, test_processed$MPG), 3), "   MAE: ",
round(MAE(predicted, test_processed$MPG), 3)))
# Accuracy of random forest model
predicted <- predict(model_lm, test_processed)
print(paste0("RMSE: ", round(RMSE(predicted, test_processed$MPG), 3), "   MAE: ",
round(MAE(predicted, test_processed$MPG), 3)))
# Accuracy of svm model
predicted <- predict(model_enet, test_processed)
print(paste0("RMSE: ", round(RMSE(predicted, test_processed$MPG), 3), "   MAE: ",
round(MAE(predicted, test_processed$MPG ), 3)))
install.packages("neuralnet")
# Linear Regression
model_lm <- classification_train(train_processed, "MPG", method = "neuralnet")
install.packages("deepnet")
library(deepnet)
# Elasticnet
model_dnn <- classification_train(train_processed, "MPG", method = "dnn")
# Elasticnet
model_dnn <- classification_train(train_processed, "Cylinders", method = "dnn")
train_processed <- train %>% dplyr::select(-Cylinders) %>%
remove_empty(cutoff = 0.40) %>%
impute(method = "median") %>%
remove_near_zero(print_results = TRUE) %>%
remove_linear_combos(print_results = TRUE) %>%
remove_correlated(cutoff = 0.78, print_results = TRUE) %>%
replace_label(train, Cylinders)
test_processed <- test %>% dplyr::select(-Cylinders) %>%
remove_empty(cutoff = 0.40) %>%
impute(method = "median") %>%
remove_near_zero(print_results = TRUE) %>%
replace_label(test, cyberbullying_type) %>%
dplyr::select(colnames(Cylinders))
test_processed <- test %>% dplyr::select(-Cylinders) %>%
remove_empty(cutoff = 0.40) %>%
impute(method = "median") %>%
remove_near_zero(print_results = TRUE) %>%
replace_label(test, Cylinders) %>%
dplyr::select(colnames(Cylinders))
train_processed <- train %>% dplyr::select(-Cylinders) %>%
remove_empty(cutoff = 0.40) %>%
impute(method = "median") %>%
remove_near_zero(print_results = TRUE) %>%
remove_linear_combos(print_results = TRUE) %>%
remove_correlated(cutoff = 0.78, print_results = TRUE) %>%
replace_label(train, Cylinders)
test_processed <- test %>% dplyr::select(-Cylinders) %>%
remove_empty(cutoff = 0.40) %>%
impute(method = "median") %>%
remove_near_zero(print_results = TRUE) %>%
replace_label(test, Cylinders) %>%
dplyr::select(colnames(Cylinders))
test
test_processed <- test %>% dplyr::select(-Cylinders) %>%
remove_empty(cutoff = 0.40) %>%
impute(method = "median") %>%
remove_near_zero(print_results = TRUE) %>%
replace_label(test, Cylinders)
test_processed
test_processed <- test %>% dplyr::select(-Cylinders) %>%
remove_empty(cutoff = 0.40) %>%
impute(method = "median") %>%
remove_near_zero(print_results = TRUE) %>%
replace_label(test, Cylinders) %>%
dplyr::select(colnames(train_processed))
test_processed
# Linear Discriminant Analysis
model_lda <- classification_train(train_processed, "cyberbullying_type", method = "lda")
# Linear Discriminant Analysis
model_lda <- classification_train(train_processed, "Cylinders", method = "lda")
# Elasticnet
model_dnn <- classification_train(train_processed, "Cylinder", method = "dnn")
# Elasticnet
model_dnn <- classification_train(train_processed, "Cylinders", method = "dnn")
# Elasticnet
model_dnn <- classification_train(train_processed, method = "dnn")
View(classification_train)
library(randomForest)
rf2 <- randomForest(x = train_processed, mtry = 2, ntree = 2000, proximity = TRUE)
rf2
prox <- rf2$proximity
pam.rf <- pam(prox, 3)
library(pam)
install.packages("pam")
pam.rf <- pam(prox, 3)
pred <- cbind(pam.rf$clustering, iris$Species)
install.packages("pamr")
library(pamr)
prox <- rf2$proximity
pam.rf <- pam(prox, 3)
pred <- cbind(pam.rf$clustering, iris$Species)
table(pred[,2], pred[,1])
pred <- cbind(pam.rf$clustering, train_processed$Cylinders)
table(pred[,2], pred[,1])
pam.rf <- pam(prox, 4)
pred <- cbind(pam.rf$clustering, train_processed$Cylinders)
table(pred[,2], pred[,1])
pam.rf <- pam(prox, 5)
pred <- cbind(pam.rf$clustering, train_processed$Cylinders)
table(pred[,2], pred[,1])
pam.rf <- pam(prox, 2)
pred <- cbind(pam.rf$clustering, train_processed$Cylinders)
table(pred[,2], pred[,1])
pam.rf <- pam(prox, 4)
pred <- cbind(pam.rf$clustering, train_processed$Cylinders)
table(pred[,2], pred[,1])
pred <- cbind(pam.rf$clustering, train_processed$MPG)
table(pred[,2], pred[,1])
pred <- cbind(pam.rf$clustering, train_processed$Cylinders)
table(pred[,2], pred[,1])
Clusters <- as.factor(pam.rf$cluster)
Clusters <- as.factor(pam.rf$cluster)
Species <- train_processed$Cylinders
ggplot(iris, aes(x = Petal.Length, y = Petal.Width, col = Clusters, pch = Species)) + geom_point(size = 3) +
scale_color_manual(values = myColRamp(3))
Clusters <- as.factor(pam.rf$cluster)
Species <- train_processed$Cylinders
ggplot(train_processed, aes(x = Cylinders, y = MPG, col = Clusters, pch = Species)) + geom_point(size = 3) +
scale_color_manual(values = myColRamp(3))
ggplot(train_processed, aes(x = Cylinders, y = MPG, col = Clusters, pch = Species)) + geom_point(size = 3)
ggplot(train_processed, aes(x = Cylinders, y = MPG, col = Clusters, pch = Species))
rf2 <- randomForest(x = mpg_copy, mtry = 2, ntree = 2000, proximity = TRUE)
rf2 <- randomForest(x = mpg_copy, mtry = 2, ntree = 2000, proximity = TRUE)
rf2
prox <- rf2$proximity
prox <- rf2$proximity
pam.rf <- pam(prox, 4)
pred <- cbind(pam.rf$clustering, mpg_copy$Cylinders)
table(pred[,2], pred[,1])
Clusters <- as.factor(pam.rf$cluster)
Clusters <- as.factor(pam.rf$cluster)
Species <- mpg_copy$Cylinders
ggplot(mpg_copy, aes(x = Cylinders, y = MPG, col = Clusters, pch = Species))
mpg_copy %>%
ggplot(aes(x = Cylinders, y = MPG)) +
geom_point(color = "#183054", alpha = .1, position = "jitter") +
ylim(0, 20000) +
labs(title = "Title",
subtitle = "Subtitle",
x = "x variable",
y = "y variable") +
theme_new +
theme(axis.title = element_text(size = 10, color = "grey40"))
mpg_copy %>%
ggplot(aes(x = Cylinders, y = MPG)) +
geom_point(color = "#183054", alpha = .1, position = "jitter") +
ylim(0, 100) +
labs(title = "Title",
subtitle = "Subtitle",
x = "x variable",
y = "y variable") +
theme_new +
theme(axis.title = element_text(size = 10, color = "grey40"))
mpg_copy %>%
ggplot(aes(x = Cylinders, y = MPG)) +
geom_point(color = "#183054", alpha = .1, position = "jitter") +
ylim(0, 50) +
labs(title = "Title",
subtitle = "Subtitle",
x = "x variable",
y = "y variable") +
theme_new +
theme(axis.title = element_text(size = 10, color = "grey40"))
mpg_copy %>%
ggplot(aes(x = Cylinders, y = MPG, color=Clusters)) +
geom_point(color = "#183054", alpha = .1, position = "jitter") +
ylim(0, 50) +
labs(title = "Title",
subtitle = "Subtitle",
x = "x variable",
y = "y variable") +
theme_new +
theme(axis.title = element_text(size = 10, color = "grey40"))
Clusters <- as.factor(pam.rf$cluster)
Species <- mpg_copy$Cylinders
Clusters
mpg_copy %>%
ggplot(aes(x = Cylinders, y = MPG, color=Clusters)) +
geom_point(color = "#183054", alpha = .1, position = "jitter") +
ylim(0, 50) +
labs(title = "Title",
subtitle = "Subtitle",
x = "x variable",
y = "y variable") +
theme_new +
theme(axis.title = element_text(size = 10, color = "grey40"))
mpg_copy %>%
ggplot(aes(x = Cylinders, y = MPG, color = Clusters)) +
geom_point(alpha = .1) +
ylim(0, 20000) +
labs(title = "Title",
subtitle = "Subtitle",
x = "x variable",
y = "y variable") +
theme_new +
theme(axis.title = element_text(size = 10, color = "grey40"),
legend.position = "right",
legend.direction = "vertical")
mpg_copy %>%
ggplot(aes(x = Cylinders, y = MPG, color = Clusters)) +
geom_point(alpha = .1) +
ylim(0, 50) +
labs(title = "Title",
subtitle = "Subtitle",
x = "x variable",
y = "y variable") +
theme_new +
theme(axis.title = element_text(size = 10, color = "grey40"),
legend.position = "right",
legend.direction = "vertical")
mpg_copy %>%
ggplot(aes(x = Cylinders, y = MPG, color = Clusters)) +
geom_point(alpha = .1, position = "jitter") +
ylim(0, 50) +
labs(title = "Title",
subtitle = "Subtitle",
x = "x variable",
y = "y variable") +
theme_new +
theme(axis.title = element_text(size = 10, color = "grey40"),
legend.position = "right",
legend.direction = "vertical")
mpg_copy %>%
ggplot(aes(x = Cylinders, y = MPG, color = Clusters, shape = Clusters)) +
geom_point(alpha = .1, position = "jitter") +
ylim(0, 50) +
labs(title = "Title",
subtitle = "Subtitle",
x = "x variable",
y = "y variable") +
theme_new +
theme(axis.title = element_text(size = 10, color = "grey40"),
legend.position = "right",
legend.direction = "vertical")
library(randomForest)
library(pamr)
rf2 <- randomForest(x = mpg_copy, mtry = 2, ntree = 2000, proximity = TRUE)
rf2
prox <- rf2$proximity
pam.rf <- pam(prox, 3)
pred <- cbind(pam.rf$clustering, mpg_copy$Cylinders)
table(pred[,2], pred[,1])
Clusters <- as.factor(pam.rf$cluster)
Species <- mpg_copy$Cylinders
mpg_copy %>%
ggplot(aes(x = Cylinders, y = MPG, color = Clusters, shape = Clusters)) +
geom_point(alpha = .1, position = "jitter") +
ylim(0, 50) +
labs(title = "Title",
subtitle = "Subtitle",
x = "x variable",
y = "y variable") +
theme_new +
theme(axis.title = element_text(size = 10, color = "grey40"),
legend.position = "right",
legend.direction = "vertical")
library(randomForest)
library(pamr)
rf2 <- randomForest(x = mpg_copy, mtry = 3, ntree = 2000, proximity = TRUE)
rf2
prox <- rf2$proximity
pam.rf <- pam(prox, 3)
pred <- cbind(pam.rf$clustering, mpg_copy$Cylinders)
table(pred[,2], pred[,1])
Clusters <- as.factor(pam.rf$cluster)
Species <- mpg_copy$Cylinders
mpg_copy %>%
ggplot(aes(x = Cylinders, y = MPG, color = Clusters, shape = Clusters)) +
geom_point(alpha = .1, position = "jitter") +
ylim(0, 50) +
labs(title = "Title",
subtitle = "Subtitle",
x = "x variable",
y = "y variable") +
theme_new +
theme(axis.title = element_text(size = 10, color = "grey40"),
legend.position = "right",
legend.direction = "vertical")
mpg_copy %>%
ggplot(aes(x = Cylinders, y = MPG, color = Clusters, shape = Clusters)) +
geom_point(alpha = .1, position = "jitter") +
ylim(0, 50) +
labs(title = "Scatterplot of Cylinders and MPG Colored by RF Clusters",
subtitle = "Note how the clusters seem to have cut data similar to MPG",
x = "Cylinders",
y = "MPG") +
theme_new +
theme(axis.title = element_text(size = 10, color = "grey40"),
legend.position = "right",
legend.direction = "vertical")
mpg_copy %>%
ggplot(aes(x = Cylinders, y = MPG, color = Clusters, shape = Clusters)) +
geom_point(alpha = .1, position = "jitter") +
ylim(0, 50) +
labs(title = "Scatterplot of Cylinders and MPG\n Colored by RF Clusters",
subtitle = "Note how the clusters seem to have cut data similar to MPG",
x = "Cylinders",
y = "MPG") +
theme_new +
theme(axis.title = element_text(size = 10, color = "grey40"),
legend.position = "right",
legend.direction = "vertical")
mpg_copy %>%
ggplot(aes(x = Cylinders, y = MPG, color = Clusters, shape = Clusters)) +
geom_point(alpha = .1, position = "jitter") +
ylim(0, 50) +
labs(title = "Scatterplot of Cylinders and MPG \nColored by RF Clusters",
subtitle = "Note how the clusters seem to have cut data similar to MPG",
x = "Cylinders",
y = "MPG") +
theme_new +
theme(axis.title = element_text(size = 10, color = "grey40"),
legend.position = "right",
legend.direction = "vertical")
# Accuracy of lda model
predicted <- predict(model_lasso, test_processed)
print(paste0("RMSE: ", round(RMSE(predicted, test_processed$MPG), 3), "   MAE: ",
round(MAE(predicted, test_processed$MPG), 3)))
# Accuracy of random forest model
predicted <- predict(model_lm, test_processed)
print(paste0("RMSE: ", round(RMSE(predicted, test_processed$MPG), 3), "   MAE: ",
round(MAE(predicted, test_processed$MPG), 3)))
# Accuracy of svm model
predicted <- predict(model_enet, test_processed)
print(paste0("RMSE: ", round(RMSE(predicted, test_processed$MPG), 3), "   MAE: ",
round(MAE(predicted, test_processed$MPG ), 3)))
# Accuracy of lda model
predicted <- predict(model_brnn, test_processed)
# Set up
# Import libraries and set graph theme
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
library(tidyverse)
library(dplyr)
library(ggplot2)
library(ggthemes)
library(caret)
library(VIM)
# Create custum theme
theme_new <-  theme_fivethirtyeight(base_size=12) %+replace% theme(panel.grid.major.y = element_line(colour = "grey80", size = 0.25),  panel.grid.major.x = element_blank(), panel.background = element_rect(fill = "white"), plot.background = element_rect(fill = "white"), legend.background = element_rect(fill = "white"))
# Make a distance matrix
d <- dist(mpg_copy)
clusters <- cutree(fitH, k = 3)
fitH <- hclust(d)
clusters <- cutree(fitH, k = 3)
plot(sample_covid[1:8], col = clusters)
plot(mpg_copy, col = clusters)
plot(mpg_copy[1:5], col = clusters)
plot(mpg_copy[1:5], col = Clusters)
# Make a distance matrix
d <- dist(mpg_copy)
# cluster using hclust
fitH <- hclust(d)
clusters <- cutree(fitH, k = 3)
# cluster using hclust
plot(mpg_copy[1:5], col = clusters)
# cluster using random forrest
plot(mpg_copy[1:5], col = Clusters)
